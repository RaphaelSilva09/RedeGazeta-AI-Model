{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light Gradient Boosting Machine - modelo de comparação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca LightGBM é uma estrutura de aumento de gradiente que usa algoritmos de aprendizagem baseados em árvore para implementar este modelo. Ele é distribuível e capaz de lidar com grandes volumes de dados com alto desempenho. LightGBM é ideal para uma variedade de tarefas de aprendizado de máquina, como classificação, regressão e ranqueamento, graças à sua velocidade e eficiência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instruções para uso local ou remoto (Google Colab ou VScode)\n",
    "\n",
    "Aqui deixaremos brevemente um passo a passo para que você usuário seja capaz de executar o código localmente ou remotamente pelo seu google drive, podendo escolher a forma mais viável para seu uso e conhecimento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Google Colab\n",
    "\n",
    "1. Faça o upload do seu arquivo .ipynb para o Google Drive.\n",
    "2. Abra o Google Colab em seu navegador.\n",
    "3. Clique em \"Arquivo\" no menu superior e selecione \"Abrir notebook\".\n",
    "4. Na guia \"Upload\", clique em \"Procurar\" e selecione o arquivo .ipynb que você enviou para o Google Drive.\n",
    "5. Após selecionar o arquivo, clique em \"Abrir\".\n",
    "6. Aguarde o carregamento do notebook no Google Colab.\n",
    "7. Agora que você carregou o notebook no Google Colab, você pode fazer as alterações necessárias nos arquivos e caminhos para se adequar ao seu ambiente específico.\n",
    "\n",
    "No notebook, a célula seguinte à essa contém as leituras dos arquivos CSV com o caminho do drive do criador desse notebook.\n",
    "Comente as linhas que fazem referência aos arquivos locais e descomente as linhas que fazem referência ao Google Drive. Por exemplo:\n",
    "\n",
    "- descomente as linhas que começam com # from google.colab import drive;\n",
    "- comente as linhas que começam com tabela_Meta = pd.read_csv(\"./data/Cópia de BASE INTELI_META_OCUP-limpo.csv\").\n",
    "\n",
    "Certifique-se de que os arquivos CSV estejam localizados no diretório correto em seu ambiente virtual. Por exemplo, se você tiver uma pasta chamada \"data\" no mesmo diretório do notebook, coloque os arquivos CSV nessa pasta e ajuste seus nomes. Possivelmente os arquivos vão seguir o seguinte padrão, mesmo no seu drive:\n",
    "\n",
    "tabela_Meta = pd.read_csv(\"/content/drive/MyDrive/NomeDaPastaDosArquivos/arquivo.csv)\n",
    "\n",
    "Salve as alterações no notebook.\n",
    "Agora você pode executar as células do notebook no Google Colab e as alterações nos arquivos e caminhos serão aplicadas ao seu ambiente do colab. Lembre-se de que você não precisará ter as bibliotecas necessárias instaladas em seu ambiente local para executar o código corretamente, dado que ao executar pela ferramenta do google essas dependências estarão aplicadas por padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VScode\n",
    "\n",
    "1. Coloque os arquivos CSV dentro da pasta \"data\" desse notebook\n",
    "\n",
    "No notebook, a célula seguinte à essa contém as leituras dos arquivos CSV com o caminho do drive do criador desse notebook.\n",
    "Comente as linhas que fazem referência aos arquivos locais e descomente as linhas que fazem referência ao Google Drive. Por exemplo:\n",
    "\n",
    "- descomente as linhas que começam com # from google.colab import drive;\n",
    "- comente as linhas que começam com tabela_Meta = pd.read_csv(\"./data/Cópia de BASE INTELI_META_OCUP-limpo.csv\").\n",
    "\n",
    "Certifique-se de que os arquivos CSV estejam localizados no diretório correto em seu ambiente virtual. Por exemplo, se você tiver uma pasta chamada \"data\" no mesmo diretório do notebook, coloque os arquivos CSV nessa pasta e ajuste seus nomes. Possivelmente os arquivos vão seguir o seguinte padrão, mesmo no seu drive:\n",
    "\n",
    "tabela_Meta = pd.read_csv(\"./data/Cópia de BASE INTELI_META_OCUP-limpo.csv\")\n",
    "\n",
    "Salve as alterações no notebook.\n",
    "Agora você pode executar as células do notebook no VScode e as alterações nos arquivos e caminhos serão aplicadas ao seu ambiente do colab. Lembre-se de que você precisará ter as bibliotecas necessárias instaladas em seu ambiente local para executar o código corretamente:\n",
    "\n",
    "Para fazer a instalação, basta abrir o terminal integrado e inserir o seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install lightgbm pandas numpy scikit-learn matplotlib shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso vamos importar as bibliotecas e dependências usadas para nosso notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightgbm as lgb # type: ignore\n",
    "    import pandas as pd # type: ignore\n",
    "    import matplotlib.pyplot as plt # type: ignore\n",
    "    from lightgbm import LGBMRegressor # type: ignore\n",
    "    from sklearn.model_selection import RandomizedSearchCV # type: ignore\n",
    "    import numpy as np # type: ignore\n",
    "    from sklearn.preprocessing import LabelEncoder # type: ignore\n",
    "    from sklearn.model_selection import train_test_split # type: ignore\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score # type: ignore\n",
    "    from math import sqrt\n",
    "    import shap\n",
    "    print(\"Todos os pacotes foram carregados com sucesso!\")\n",
    "except ModuleNotFoundError as e:\n",
    "    print(f\"Erro ao carregar pacotes: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos importar as tabelas já limpas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pegando arquivos csv do drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Lendo os arquivos CSV\n",
    "# tabela_Meta = pd.read_csv(\"/content/drive/MyDrive/Primeiro Ano/Módulo 3 - Modelo Preditivo Gazeta/Base de Dados Limpas/BASE INTELI_META-limpo.csv\")\n",
    "# tabela_Agosto = pd.read_csv(\"/content/drive/MyDrive/Primeiro Ano/Módulo 3 - Modelo Preditivo Gazeta/Base de Dados Limpas/tratada_BaseDados_ProjetoINTELI_RG_01_AGOSTO_2024.csv\")\n",
    "\n",
    "# para realizar o processo localmente, descomente as linhas abaixo e comente as linhas acima.\n",
    "tabela_Meta = pd.read_csv(\"../data/dados_tratados/BASE INTELI_META-limpo.csv\")\n",
    "tabela_Agosto = pd.read_csv(\"../data/dados_tratados/tratada_BaseDados_ProjetoINTELI_RG_01_AGOSTO_2024.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os arquivos em mão, vamos definir valores máximos no formato de exibição e agrupar colunas, visando somar as de valor númerico de acordo com as exigências do parceiro. No fim, a saída mostrará uma representação da tabela filtrada com as features usadas será mostrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo formato de exibição\n",
    "pd.set_option('display.float_format', '{:.0f}'.format)\n",
    "\n",
    "# Agrupar e somar 'Vl Liquido Final' e 'Outra Coluna'\n",
    "tabela_agosto_segmento = tabela_Agosto.groupby(['Ano', 'Mês', 'Veiculo', 'Origem', 'Segmento']).agg({\n",
    "    'Vl Liquido Final': 'sum',\n",
    "    # 'VL Tabela': 'sum'\n",
    "\n",
    "}).reset_index()\n",
    "\n",
    "# tabela_agosto_segmento['VL Tabela'] = tabela_agosto_segmento['VL Tabela'] / 1000\n",
    "tabela_agosto_segmento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Abaixo, as colunas categóricas (aquelas que contém texto) serão transformadas em numéricas, de modo a pouco comprometer o desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['Veiculo', 'Origem', 'Segmento']\n",
    "X = tabela_agosto_segmento.drop('Vl Liquido Final', axis=1)\n",
    "y = tabela_agosto_segmento['Vl Liquido Final']\n",
    "\n",
    "label_encoders = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "    label_encoders[col] = le\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após, faremos a divisão das amostras de treinamento e teste do modelo, e depois o ajuste do modelo com o grupo de treino, equivalente à 30% da base total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4)\n",
    "\n",
    "modelo = lgb.LGBMRegressor()\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search\n",
    "\n",
    "Usando grid search, podemos encontrar os hyperparâmetros ideais para o modelo de machine learning. Funciona por meio de uma busca abrangente em um subconjunto específico do espaço hiperparamétrico.\n",
    "\n",
    "Em resumo, essa técnica permite que testemos diversos modelos com diferentes parâmetros de entrada de forma automática, ao criar intervalos que desejamos que o modelo seja testado.\n",
    "\n",
    "Nota: devido ao longo tempo de execução, o código responsável está comentado, mas seu output será usado nos blocos de código posteriores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': list(range(40, 500)),\n",
    "#     'learning_rate': [0.01, 0.1, 0.2],\n",
    "#     'max_depth': [3, 4, 5, 6, 7, 9 , 11, 13, 15],\n",
    "#     'subsample': [0.1, 0.3, 0.4, 0.7, 1],\n",
    "#     'min_child_weight': [0.5, 1, 2, 3, 4, 5],\n",
    "#     'colsample_bytree': [0.7, 0.8, 1], \n",
    "#     'reg_alpha': [0, 0.01, 0.1],        \n",
    "#     'reg_lambda': [1, 1.5, 2]           \n",
    "# }\n",
    "\n",
    "# # Configurando o Grid Search com validação cruzada\n",
    "# grid_search = RandomizedSearchCV(\n",
    "#     estimator=LGBMRegressor(),\n",
    "#     param_distributions=param_grid,\n",
    "#     scoring='neg_mean_absolute_error',\n",
    "#     cv=10,\n",
    "#     verbose=0,\n",
    "#     n_jobs=8,\n",
    "#     n_iter=500\n",
    "# )\n",
    "\n",
    "# # Ajustando o Grid Search ao conjunto de dados\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # Imprimindo os melhores parâmetros e o melhor resultado\n",
    "# print(\"Melhores Parâmetros:\", grid_search.best_params_)\n",
    "# print(\"Melhor MAE:\", -grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos os melhores parâmetros, ajustaremos o modelo conforme aos melhores resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = lgb.LGBMRegressor(subsample=0.1, reg_lambda=1, reg_alpha=0.1, n_estimators=493, min_child_weight=5, max_depth=13, learning_rate=0.1, colsample_bytree=1)\n",
    "modelo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, faremos o modelo realizar previsões com a porcentagem de 70% da base que foi destinada a esse teste.\n",
    "\n",
    "Podemos ver na saída desse bloco de código as métricas usadas para validar a eficiência do modelo, explicaremos elas em breve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) / 10\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {sqrt(rmse)}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "print(f'MPAE: {mape:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erro Médio Absoluto (MAE - do inglês *Mean Absoluto Error*)\n",
    "\n",
    "O MAE é uma métrica utilizada para avaliar a qualidade de modelos de regressão, calculando a média das diferenças absolutas entre os valores reais e os valores preditos. Quanto menor o valor do MAE, melhor o desempenho do modelo. Abaixo, apresentamos o cálculo desse indicador no modelo do grupo:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raiz do Erro Quadrático Médio (RMSE - do inglês *Root Mean Squared Error*)\n",
    "\n",
    "O RMSE (Root Mean Squared Error) é uma métrica de avaliação utilizada em modelos de regressão que, assim como o MSE (Mean Squared Error), mede a diferença entre os valores reais e os valores previstos. No RMSE, essa diferença é elevada ao quadrado, o que elimina os sinais negativos e dá mais peso a grandes erros. A diferença principal está no fato de que, ao final, é aplicada a raiz quadrada no valor resultante, tornando a métrica mais interpretável, pois os erros são trazidos de volta à mesma escala das variáveis originais. Portanto, quanto menor o RMSE, melhor o desempenho do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Root Mean Squared Error: {sqrt(rmse)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coeficiente de Determinação (R²)\n",
    "\n",
    "O Coeficiente de Determinação R² é uma métrica que representa o percentual da variância dos dados previstos, ou seja, o quão explicativo é o modelo em relação aos dados de acordo com o quão distante esses valores estão do valor central (médio). Uma vez que a fórmula do R² considera a subtração desta conta por 1, quando menor o percentual obtido, melhor é a explicação do modelo. Este, no entanto, não é suficiente para ter uma noção geral da performace do modelo, dependendo de outras métricas (como o MAE e o MSE). Abaixo, apresentamos o cálculo desse indicador no modelo do grupo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R² Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erro Percentual Médio Absoluto (MAPE)\n",
    "\n",
    "O Erro Percentual Médio Absoluto (MAPE) mede a precisão de modelos de regressão, calculando a média dos erros percentuais absolutos entre os valores previstos e reais. Ao expressar o erro como uma proporção entre 0 e 1, o MAPE facilita a interpretação do desempenho relativo do modelo. Quanto mais próximo de 0, melhor a precisão; valores próximos de 1 indicam maiores erros. Embora seja útil para avaliar a precisão relativa, o MPAE deve ser complementado por outras métricas para uma análise mais completa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) / 10\n",
    "print(f'MPAE: {mape:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir, vamos analisar os resultados visualmente:\n",
    "\n",
    "O gráfico compara os valores reais com as previsões do modelo. A linha roxa representa as previsões geradas pelo modelo, enquanto os pontos vermelhos correspondem aos valores reais. Quanto mais próximos os pontos estiverem da linha, melhor a qualidade das previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, color='red', alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='purple', lw=3)\n",
    "plt.xlabel('Valores Reais')\n",
    "plt.ylabel('Previsões')\n",
    "plt.title('Comparação entre Valores Reais e Previsões - Modelo LightGBM')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conlusões\n",
    "\n",
    "Apesar de obter resultados factualmente positivos, é nítido que ao compararmos com o modelo entregue na sprint 3 de desenvolvimento, ainda existe uma desvantagem entre o resultado do LightGBM em relação ao Random Forest Regressor, como observado à seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métrica | Random Forest Regressor | Light GBM Regressor\n",
    "--- | --- | ---\n",
    "R² | 91% | 90%\n",
    "MAE | 10.417 | 13.329\n",
    "RMSE | 31.757 | 33.536\n",
    "MAPE | 0,40 | 0,77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O R² do LightGBM é apenas 1% menor, indicando que ambos os modelos explicam bem a variabilidade dos dados. No entanto, o MAE e o RMSE mostram que o Random Forest possui menor erro absoluto e quadrático, respectivamente, sugerindo uma performance mais precisa. O MAPE reforça essa tendência, com o erro percentual absoluto do LightGBM sendo quase o dobro do Random Forest (0,77 contra 0,40), apontando para uma menor precisão nas previsões do LightGBM na comparação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicabilidade\n",
    "A explicabilidade de um modelo preditivo refere-se à capacidade de compreender e interpretar como um modelo toma suas decisões ou faz previsões. Isso é particularmente importante em modelos complexos onde o processo de decisão não é facilmente visível para os seres humanos. Logo abaixo, vamos iniciar a explicabilidade do modelo para conferir como as previsões foram realizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um objeto explainer SHAP\n",
    "explainer = shap.Explainer(modelo, X_train)\n",
    "\n",
    "# Calcule os valores SHAP para as previsões\n",
    "shap_values = explainer(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary Plot\n",
    "Esse gráfico de resumo mostra a importância global das variáveis no modelo, bem como a distribuição dos valores SHAP (impacto no resultado do modelo) para cada variável. Ele mostra como cada variável impacta globalmente o modelo e sua distribuição nos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eixo Y: Lista as variáveis/features do modelo, como \"Segmento\", \"Veículo\", \"Origem\", etc.\n",
    "- Eixo X: Representa os valores SHAP, que indicam o impacto da variável no resultado do modelo. Valores positivos aumentam a previsão, enquanto valores negativos a reduzem.\n",
    "- Pontos: Cada ponto representa uma observação (amostra) dos seus dados.\n",
    "A cor do ponto indica o valor da variável: azul para valores baixos, vermelho para valores altos.\n",
    "A posição horizontal do ponto indica o impacto que aquela observação teve no resultado. Quanto mais à direita, maior o impacto positivo na previsão; quanto mais à esquerda, maior o impacto negativo.\n",
    "\n",
    "A variável Segmento tem um impacto maior em geral, com muitos pontos azuis e vermelhos espalhados. Isso indica que, dependendo do valor da variável (seja alto ou baixo), ela pode ter um impacto positivo ou negativo nas previsões.\n",
    "Origem também tem uma distribuição de valores SHAP, mas tem menos impacto em comparação com \"Segmento\" e \"Veículo\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waterfall Plot\n",
    "Este gráfico explica a previsão individual de um dado ponto de teste. Ele decompõe o valor predito em contribuições individuais de cada variável. O valor final predito é a soma da base do modelo com as contribuições de cada variável. Ou seja, ele explica como cada variável contribui para a previsão de um ponto específico, mostrando o impacto individual de cada uma na previsão final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mostra como cada recurso impactou uma previsão específica.\n",
    "shap.waterfall_plot(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f(x): O valor predito para essa observação específica (no caso, aproximadamente -47675.89).\n",
    "- Base value: O valor de referência do modelo, antes de considerar os efeitos das variáveis (aproximadamente 47850.108).\n",
    "- Barras Azuis/Vermelhas:\n",
    "Barras azuis indicam que a variável diminuiu a previsão em relação ao valor base.\n",
    "Barras vermelhas indicam que a variável aumentou a previsão.\n",
    "Cada barra mostra o valor da variável e seu impacto específico na previsão.\n",
    "\n",
    "A variável Segmento (com valor 7) reduziu a previsão em -36360.5.\n",
    "A variável Veículo (com valor 13) também teve um impacto negativo, reduzindo a previsão em -39085.32.\n",
    "Por outro lado, a variável origem aumentou a precisão em 2799.62."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
